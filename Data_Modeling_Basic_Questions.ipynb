{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtUGUSxx8WCLDal0+2Y2am",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/connecttopawan/Databricks-Certified-Data-Engineer-Professional/blob/main/Data_Modeling_Basic_Questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1\n",
        "What is the primary purpose of data modeling in a data engineering context?\n",
        "\n",
        "**A.** To optimize data storage costs  \n",
        "**B.** To define the structure and relationships of data in a database  \n",
        "**C.** To automate data ingestion pipelines  \n",
        "**D.** To visualize data for business users  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Data modeling involves defining the structure, relationships, and constraints of data within a database to ensure it meets business requirements and supports efficient querying and storage. It is not primarily about cost optimization (A), pipeline automation (C), or visualization (D).\n",
        "\n",
        "---\n",
        "\n",
        "## Question 2\n",
        "Which of the following is a characteristic of a **normalized** database schema?\n",
        "\n",
        "**A.** Redundant data is stored to improve query performance  \n",
        "**B.** Data is split into multiple tables to reduce redundancy  \n",
        "**C.** All tables are denormalized for faster reads  \n",
        "**D.** Complex joins are avoided by storing all data in a single table  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Normalization organizes data into multiple tables to eliminate redundancy and ensure data integrity, reducing anomalies during insert, update, or delete operations. Options A, C, and D describe denormalized schemas.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 3\n",
        "In a Databricks environment, why might you choose to denormalize a database schema?\n",
        "\n",
        "**A.** To enforce strict data integrity constraints  \n",
        "**B.** To improve query performance for analytical workloads  \n",
        "**C.** To reduce the number of joins required in transactional systems  \n",
        "**D.** To ensure compliance with GDPR regulations  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Denormalization in a Databricks environment is often used to improve query performance for analytical workloads by reducing the need for complex joins and enabling faster reads, especially in big data scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 4\n",
        "What is a key benefit of using a **star schema** in a data warehouse?\n",
        "\n",
        "**A.** It eliminates the need for fact tables  \n",
        "**B.** It simplifies queries by reducing the number of joins  \n",
        "**C.** It enforces strict normalization rules  \n",
        "**D.** It is optimized for transactional processing  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A star schema consists of a central fact table surrounded by dimension tables, simplifying queries by reducing the number of joins compared to a normalized schema. It is designed for analytical processing, not transactional systems (D).\n",
        "\n",
        "---\n",
        "\n",
        "## Question 5\n",
        "In a **snowflake schema**, how do dimension tables differ from those in a star schema?\n",
        "\n",
        "**A.** They are fully denormalized  \n",
        "**B.** They are normalized into multiple related tables  \n",
        "**C.** They contain measures instead of attributes  \n",
        "**D.** They are stored in a separate database  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** In a snowflake schema, dimension tables are normalized into multiple related tables, creating a more complex structure than the denormalized dimension tables in a star schema.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 6\n",
        "Which Delta Lake feature supports schema evolution in a data model?\n",
        "\n",
        "**A.** Time Travel  \n",
        "**B.** Schema Enforcement  \n",
        "**C.** Schema Evolution  \n",
        "**D.** Z-Ordering  \n",
        "\n",
        "**Correct Answer:** C  \n",
        "**Explanation:** Delta Lake's schema evolution feature allows you to modify a table's schema (e.g., adding new columns) without breaking existing data pipelines, making it ideal for evolving data models in a lakehouse.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 7\n",
        "When designing a data model for a Databricks lakehouse, what is a key consideration?\n",
        "\n",
        "**A.** Ensuring all data is stored in a single table  \n",
        "**B.** Balancing query performance with storage efficiency  \n",
        "**C.** Avoiding partitioning to simplify management  \n",
        "**D.** Using only relational databases for storage  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** In a Databricks lakehouse, data modeling requires balancing query performance (e.g., through partitioning or denormalization) with storage efficiency to optimize costs and scalability.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 8\n",
        "What is the purpose of a **fact table** in a star schema?\n",
        "\n",
        "**A.** To store descriptive attributes about business entities  \n",
        "**B.** To store quantitative metrics or measures  \n",
        "**C.** To define relationships between dimension tables  \n",
        "**D.** To enforce referential integrity constraints  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A fact table in a star schema contains quantitative metrics or measures (e.g., sales amounts, counts) and foreign keys linking to dimension tables, which store descriptive attributes (A).\n",
        "\n",
        "---\n",
        "\n",
        "## Question 9\n",
        "Which of the following is a disadvantage of a highly normalized schema in a Databricks environment?\n",
        "\n",
        "**A.** Increased storage requirements  \n",
        "**B.** Slower query performance due to multiple joins  \n",
        "**C.** Inability to support schema evolution  \n",
        "**D.** Lack of support for Delta Lake features  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Highly normalized schemas require multiple joins, which can slow query performance in analytical workloads, especially in big data environments like Databricks.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 10\n",
        "What is a **surrogate key** in data modeling?\n",
        "\n",
        "**A.** A natural key derived from business data  \n",
        "**B.** A unique, system-generated identifier for a record  \n",
        "**C.** A foreign key linking two fact tables  \n",
        "**D.** A composite key combining multiple attributes  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A surrogate key is a unique, system-generated identifier (e.g., an auto-incrementing ID) used to uniquely identify records in a table, independent of business data.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 11\n",
        "In Databricks, how can **partitioning** a Delta table improve query performance?\n",
        "\n",
        "**A.** By reducing the number of rows scanned during queries  \n",
        "**B.** By enforcing schema constraints  \n",
        "**C.** By automatically indexing all columns  \n",
        "**D.** By eliminating the need for joins  \n",
        "\n",
        "**Correct Answer:** A  \n",
        "**Explanation:** Partitioning a Delta table organizes data into subsets based on column values, reducing the number of rows scanned during queries and improving performance.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 12\n",
        "Which of the following is true about **denormalization** in a data warehouse?\n",
        "\n",
        "**A.** It increases data redundancy to improve read performance  \n",
        "**B.** It reduces the number of tables to enforce normalization  \n",
        "**C.** It is primarily used for transactional systems  \n",
        "**D.** It eliminates the need for dimension tables  \n",
        "\n",
        "**Correct Answer:** A  \n",
        "**Explanation:** Denormalization intentionally introduces data redundancy to reduce joins and improve read performance, which is common in data warehouses for analytical queries.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 13\n",
        "What is the role of a **dimension table** in a star schema?\n",
        "\n",
        "**A.** To store quantitative measures  \n",
        "**B.** To store descriptive attributes about business entities  \n",
        "**C.** To link multiple fact tables together  \n",
        "**D.** To enforce data integrity constraints  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Dimension tables in a star schema store descriptive attributes (e.g., product names, customer details) that provide context to the measures in fact tables.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 14\n",
        "When would you use a **snowflake schema** over a star schema in a Databricks data warehouse?\n",
        "\n",
        "**A.** When query simplicity is the primary goal  \n",
        "**B.** When storage efficiency and data normalization are priorities  \n",
        "**C.** When real-time transactional processing is required  \n",
        "**D.** When all data must be stored in a single table  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A snowflake schema normalizes dimension tables, reducing redundancy and improving storage efficiency, but it increases query complexity compared to a star schema.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 15\n",
        "Which Delta Lake feature ensures that a table's schema remains consistent during writes?\n",
        "\n",
        "**A.** Time Travel  \n",
        "**B.** Schema Enforcement  \n",
        "**C.** Z-Ordering  \n",
        "**D.** Delta Sharing  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Schema Enforcement in Delta Lake ensures that data written to a table conforms to the defined schema, preventing inconsistencies.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 16\n",
        "What is a **composite key** in data modeling?\n",
        "\n",
        "**A.** A single column that uniquely identifies a record  \n",
        "**B.** A combination of two or more columns that uniquely identify a record  \n",
        "**C.** A foreign key linking to a dimension table  \n",
        "**D.** A system-generated key for indexing  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A composite key is a combination of two or more columns that together uniquely identify a record in a table.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 17\n",
        "In a Databricks lakehouse, why might you avoid over-normalizing a data model?\n",
        "\n",
        "**A.** To reduce storage costs  \n",
        "**B.** To improve query performance for analytical workloads  \n",
        "**C.** To simplify schema evolution  \n",
        "**D.** To enforce stricter data integrity  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Over-normalization can lead to complex joins, which slow down analytical queries in a Databricks lakehouse, where performance is often prioritized.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 18\n",
        "What is the purpose of **Z-Ordering** in a Delta Lake table?\n",
        "\n",
        "**A.** To enforce schema constraints  \n",
        "**B.** To optimize data layout for faster queries  \n",
        "**C.** To enable time travel queries  \n",
        "**D.** To partition data by date  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Z-Ordering in Delta Lake organizes data to improve query performance by co-locating related data, reducing the amount of data scanned.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 19\n",
        "Which of the following is a benefit of using a **star schema** in Databricks?\n",
        "\n",
        "**A.** Reduced storage requirements due to normalization  \n",
        "**B.** Simplified queries for business intelligence tools  \n",
        "**C.** Support for real-time transactional updates  \n",
        "**D.** Elimination of fact tables  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A star schema simplifies queries for BI tools by reducing the number of joins and providing a clear structure for analytical queries.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 20\n",
        "What is a key difference between a **data warehouse** and a **data lake** in terms of data modeling?\n",
        "\n",
        "**A.** Data warehouses use unstructured data, while data lakes use structured data  \n",
        "**B.** Data warehouses use schema-on-write, while data lakes use schema-on-read  \n",
        "**C.** Data lakes are optimized for transactional processing  \n",
        "**D.** Data warehouses cannot store historical data  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Data warehouses enforce a schema-on-write approach, requiring a predefined schema, while data lakes use schema-on-read, allowing flexibility in schema definition during querying.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 21\n",
        "In a Databricks environment, what is a potential downside of denormalization?\n",
        "\n",
        "**A.** Increased query complexity  \n",
        "**B.** Higher storage costs due to data redundancy  \n",
        "**C.** Slower write performance  \n",
        "**D.** Inability to support joins  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Denormalization increases storage costs due to redundant data, but it improves read performance by reducing the need for joins.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 22\n",
        "What is the purpose of a **foreign key** in a data model?\n",
        "\n",
        "**A.** To uniquely identify a record in a table  \n",
        "**B.** To establish a relationship between two tables  \n",
        "**C.** To store quantitative measures  \n",
        "**D.** To partition a table for performance  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A foreign key is a column (or set of columns) in one table that references the primary key of another table, establishing a relationship between them.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 23\n",
        "When designing a data model for a Delta Lake table, what is a benefit of using **partitioning**?\n",
        "\n",
        "**A.** It eliminates the need for indexing  \n",
        "**B.** It reduces the amount of data scanned during queries  \n",
        "**C.** It enforces schema evolution  \n",
        "**D.** It prevents data updates  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Partitioning organizes data into subsets based on column values, reducing the amount of data scanned during queries and improving performance.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 24\n",
        "Which of the following is true about a **snowflake schema**?\n",
        "\n",
        "**A.** It is less normalized than a star schema  \n",
        "**B.** It reduces storage requirements but increases query complexity  \n",
        "**C.** It is optimized for transactional processing  \n",
        "**D.** It eliminates the need for dimension tables  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A snowflake schema normalizes dimension tables, reducing storage requirements but increasing query complexity due to additional joins.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 25\n",
        "What is the purpose of **schema evolution** in Delta Lake?\n",
        "\n",
        "**A.** To enforce strict schema constraints  \n",
        "**B.** To allow changes to a table's schema without breaking pipelines  \n",
        "**C.** To optimize data storage costs  \n",
        "**D.** To enable real-time data ingestion  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Schema evolution in Delta Lake allows you to modify a table's schema (e.g., adding columns) without disrupting existing data pipelines.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 26\n",
        "Which of the following is a characteristic of a **fact table** in a star schema?\n",
        "\n",
        "**A.** It contains descriptive attributes  \n",
        "**B.** It contains foreign keys linking to dimension tables  \n",
        "**C.** It is fully normalized  \n",
        "**D.** It is used to store metadata  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A fact table contains quantitative measures and foreign keys that link to dimension tables, which store descriptive attributes.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 27\n",
        "Why might you choose to use a **star schema** in a Databricks data warehouse?\n",
        "\n",
        "**A.** To enforce strict normalization  \n",
        "**B.** To simplify analytical queries for BI tools  \n",
        "**C.** To support real-time transactional updates  \n",
        "**D.** To reduce the number of dimension tables  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A star schema simplifies analytical queries for BI tools by reducing the number of joins and providing a clear structure.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 28\n",
        "In a Databricks lakehouse, what is a benefit of using **Delta Lake** for data modeling?\n",
        "\n",
        "**A.** It eliminates the need for data modeling  \n",
        "**B.** It supports ACID transactions and schema enforcement  \n",
        "**C.** It prevents schema evolution  \n",
        "**D.** It requires all data to be normalized  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Delta Lake supports ACID transactions, schema enforcement, and schema evolution, making it ideal for robust data modeling in a lakehouse.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 29\n",
        "What is a **natural key** in data modeling?\n",
        "\n",
        "**A.** A system-generated unique identifier  \n",
        "**B.** A column or set of columns with business meaning that uniquely identifies a record  \n",
        "**C.** A foreign key linking to a fact table  \n",
        "**D.** A composite key used for indexing  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A natural key is a column (or set of columns) with business meaning (e.g., a customer ID) that uniquely identifies a record, unlike a surrogate key (A).\n",
        "\n",
        "---\n",
        "\n",
        "## Question 30\n",
        "When might you use **denormalization** in a Databricks environment?\n",
        "\n",
        "**A.** To enforce strict data integrity  \n",
        "**B.** To improve query performance for large-scale analytics  \n",
        "**C.** To reduce the number of tables  \n",
        "**D.** To support real-time transactional processing  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Denormalization is used in Databricks to improve query performance for large-scale analytical workloads by reducing joins and redundancy.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 31\n",
        "What is the purpose of a **primary key** in a data model?\n",
        "\n",
        "**A.** To store descriptive attributes  \n",
        "**B.** To uniquely identify each record in a table  \n",
        "**C.** To link to a fact table  \n",
        "**D.** To partition data for performance  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A primary key is a column (or set of columns) that uniquely identifies each record in a table, ensuring data integrity.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 32\n",
        "In a star schema, what is the role of a **dimension table**?\n",
        "\n",
        "**A.** To store quantitative measures  \n",
        "**B.** To store descriptive attributes about business entities  \n",
        "**C.** To enforce schema constraints  \n",
        "**D.** To partition data for performance  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Dimension tables store descriptive attributes (e.g., product names, customer details) that provide context to the measures in fact tables.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 33\n",
        "What is a benefit of using **Z-Ordering** in a Delta Lake table?\n",
        "\n",
        "**A.** It enforces schema evolution  \n",
        "**B.** It improves query performance by optimizing data layout  \n",
        "**C.** It eliminates the need for partitioning  \n",
        "**D.** It supports real-time data ingestion  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Z-Ordering optimizes the physical layout of data in a Delta Lake table, improving query performance by co-locating related data.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 34\n",
        "Which of the following is true about a **data lakehouse** in Databricks?\n",
        "\n",
        "**A.** It only supports structured data  \n",
        "**B.** It combines the flexibility of a data lake with the structure of a data warehouse  \n",
        "**C.** It is optimized for transactional processing  \n",
        "**D.** It eliminates the need for data modeling  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A data lakehouse in Databricks combines the flexibility of a data lake (schema-on-read) with the structure of a data warehouse (schema-on-write).\n",
        "\n",
        "---\n",
        "\n",
        "## Question 35\n",
        "What is a disadvantage of a **snowflake schema** in a Databricks data warehouse?\n",
        "\n",
        "**A.** Increased storage requirements  \n",
        "**B.** Increased query complexity due to additional joins  \n",
        "**C.** Inability to support analytical queries  \n",
        "**D.** Lack of support for Delta Lake  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A snowflake schema increases query complexity due to the normalization of dimension tables, requiring more joins than a star schema.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 36\n",
        "In Delta Lake, what does **schema enforcement** prevent?\n",
        "\n",
        "**A.** Adding new columns to a table  \n",
        "**B.** Writing data that violates the defined schema  \n",
        "**C.** Querying historical data  \n",
        "**D.** Partitioning a table  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Schema enforcement in Delta Lake prevents writing data that does not conform to the table’s defined schema, ensuring data consistency.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 37\n",
        "What is the purpose of **data modeling** in a Databricks lakehouse?\n",
        "\n",
        "**A.** To eliminate the need for ETL pipelines  \n",
        "**B.** To define the structure and relationships of data for efficient querying  \n",
        "**C.** To enforce real-time data ingestion  \n",
        "**D.** To reduce the need for data storage  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Data modeling defines the structure and relationships of data to support efficient querying and analysis in a Databricks lakehouse.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 38\n",
        "Which of the following is a benefit of using a **star schema** over a snowflake schema?\n",
        "\n",
        "**A.** Reduced storage requirements  \n",
        "**B.** Simplified queries with fewer joins  \n",
        "**C.** Support for transactional processing  \n",
        "**D.** Elimination of fact tables  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A star schema simplifies queries by using denormalized dimension tables, requiring fewer joins than a snowflake schema.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 39\n",
        "What is a **surrogate key** used for in a data warehouse?\n",
        "\n",
        "**A.** To store business-relevant data  \n",
        "**B.** To uniquely identify records without relying on business data  \n",
        "**C.** To link fact tables to other fact tables  \n",
        "**D.** To partition data for performance  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A surrogate key is a system-generated identifier used to uniquely identify records, independent of business data, improving performance and stability.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 40\n",
        "In a Databricks environment, what is a benefit of using **Delta Lake** for data modeling?\n",
        "\n",
        "**A.** It eliminates the need for schema design  \n",
        "**B.** It supports ACID transactions and schema evolution  \n",
        "**C.** It prevents data updates  \n",
        "**D.** It requires all data to be denormalized  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Delta Lake supports ACID transactions, schema enforcement, and schema evolution, making it ideal for robust data modeling.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 41\n",
        "What is the purpose of **partitioning** a Delta Lake table?\n",
        "\n",
        "**A.** To enforce schema constraints  \n",
        "**B.** To improve query performance by reducing data scanned  \n",
        "**C.** To eliminate the need for joins  \n",
        "**D.** To support real-time data ingestion  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Partitioning organizes data into subsets, reducing the amount of data scanned during queries and improving performance.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 42\n",
        "Which of the following is a characteristic of a **denormalized** schema?\n",
        "\n",
        "**A.** Reduced redundancy to improve storage efficiency  \n",
        "**B.** Increased redundancy to improve query performance  \n",
        "**C.** Strict enforcement of normalization rules  \n",
        "**D.** Elimination of dimension tables  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Denormalization increases redundancy to reduce joins and improve query performance, especially for analytical workloads.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 43\n",
        "What is a **foreign key** in a data model?\n",
        "\n",
        "**A.** A column that uniquely identifies a record  \n",
        "**B.** A column that references a primary key in another table  \n",
        "**C.** A system-generated identifier  \n",
        "**D.** A column used for partitioning  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A foreign key is a column that references the primary key of another table, establishing a relationship between the tables.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 44\n",
        "Why might you use a **snowflake schema** in a Databricks data warehouse?\n",
        "\n",
        "**A.** To simplify queries for BI tools  \n",
        "**B.** To reduce storage requirements through normalization  \n",
        "**C.** To support real-time transactional updates  \n",
        "**D.** To eliminate the need for fact tables  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A snowflake schema normalizes dimension tables, reducing storage requirements but increasing query complexity due to additional joins.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 45\n",
        "In Delta Lake, what does **schema evolution** allow you to do?\n",
        "\n",
        "**A.** Enforce strict schema constraints  \n",
        "**B.** Modify a table’s schema without breaking pipelines  \n",
        "**C.** Eliminate the need for partitioning  \n",
        "**D.** Support real-time data ingestion  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Schema evolution allows you to modify a table’s schema (e.g., adding columns) without disrupting existing data pipelines.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 46\n",
        "What is the role of a **fact table** in a star schema?\n",
        "\n",
        "**A.** To store descriptive attributes  \n",
        "**B.** To store quantitative measures and foreign keys  \n",
        "**C.** To enforce schema constraints  \n",
        "**D.** To partition data for performance  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A fact table stores quantitative measures (e.g., sales amounts) and foreign keys linking to dimension tables.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 47\n",
        "What is a benefit of using a **star schema** in a Databricks data warehouse?\n",
        "\n",
        "**A.** Reduced storage requirements  \n",
        "**B.** Simplified queries for analytical workloads  \n",
        "**C.** Support for transactional processing  \n",
        "**D.** Elimination of dimension tables  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A star schema simplifies queries for analytical workloads by reducing the number of joins, making it ideal for BI tools.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 48\n",
        "In a Databricks lakehouse, what is a key consideration when designing a data model?\n",
        "\n",
        "**A.** Avoiding partitioning to simplify management  \n",
        "**B.** Balancing query performance and storage efficiency  \n",
        "**C.** Using only normalized schemas  \n",
        "**D.** Eliminating the need for schema evolution  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Data modeling in a Databricks lakehouse requires balancing query performance (e.g., through partitioning or denormalization) with storage efficiency.\n",
        "\n",
        "---\n",
        "\n",
        "## Question 49\n",
        "What is a **natural key** in a data model?\n",
        "\n",
        "**A.** A system-generated identifier  \n",
        "**B.** A column with business meaning that uniquely identifies a record  \n",
        "**C.** A foreign key linking to a fact table  \n",
        "**D.** A composite key used for indexing  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** A natural key is a column with business meaning (e.g., a customer ID) that uniquely identifies a record, unlike a surrogate key (A).\n",
        "\n",
        "---\n",
        "\n",
        "## Question 50\n",
        "Why might you use **Z-Ordering** in a Delta Lake table?\n",
        "\n",
        "**A.** To enforce schema constraints  \n",
        "**B.** To optimize data layout for faster queries  \n",
        "**C.** To eliminate the need for partitioning  \n",
        "**D.** To support real-time data ingestion  \n",
        "\n",
        "**Correct Answer:** B  \n",
        "**Explanation:** Z-Ordering optimizes the physical layout of data in a Delta Lake table, improving query performance by co-locating related data.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7Og0XWUATeIS"
      }
    }
  ]
}